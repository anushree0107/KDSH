intra-group uniformity and considering the impact of different popularity levels in the training. We prefer to push away items
within the same group to optimize uniformity. This setup helps prevent over-optimizing the uniformity of different groups, thereby
mitigating representation separation.
The final re-weighting contrastive objective is the weighted sum of the user objective and the item objective:
LCL=1
2Ã—(LCL
item+LCL
user). (6)
In this way, we not only achieved consistency in representation but also reduced the risk of further separating items with similar
characteristics into different representation spaces, thereby alleviating the issue of representation separation caused by popularity
bias.
2.3 Model Optimization
layer for the constrained predictors, G0andG1. Training uses a sampled subset of points from
the input space. Figure 3 shows an example of applying our safe predictor to a notional regression
problem with a 2-D input and 1-D output, using two overlapping constraints. The unconstrained
network has two hidden layers of dimension 20 and ReLU activations, followed by a fully connected
layer. The constrained predictors, G00,G10,G01, and G11, share the hidden layers but also have an
additional hidden layer of size 20 with ReLU, followed by a fully connected layer. Training uses a
sampled subset of points from the input space.
 The training uses a sampled subset of points from the input space and the learned
predictors are shown for the continuous input space.
Figure 3 shows an example of applying the safe predictor to a notional regression problem with a 2-D
input and 1-D output and two overlapping constraints. The unconstrained network has two hidden
layers of dimension 20 with ReLU activations, followed by a fully connected layer. The constrained
predictors G00,G10,G01andG11share the hidden layers and have an additional hidden layer of size
20 with ReLU followed by a fully connected layer. Again, training uses a sampled subset of points
from the input space and the learned predictors are shown for the continuous input space.
