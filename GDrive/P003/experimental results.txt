 The scaling factor S=lreal/lavgis applied to the clean food mesh
RCf, resulting in the final scaled food mesh RFfin meters.
The team uses depth information along with food and reference object masks to validate the scaling
factors. The method for assessing food size involves using overhead RGB images for each scene.
Initially, the pixel-per-unit (PPU) ratio (in meters) is determined using the reference object. Subse-
quently, the food width ( fw) and length ( fl) are extracted using a food object mask. To determine the
food height ( fh), a two-step process is followed. First, binary image segmentation is performed using
of complexity: easy (200 images), medium (30 images), and hard (1 image). A
total of 16 teams participated in the final assessment phase. The methodologies
developed during this challenge have yielded highly encouraging outcomes in
3D food reconstruction, showing great promise for refining portion estimation in
dietary evaluations and nutritional tracking. Further information on this workshop
challenge and the dataset is accessible via the provided URL.
1 Introduction
The convergence of computer vision technologies with culinary practices has pioneered innovative
approaches to dietary monitoring and nutritional assessment. The MetaFood Workshop Challenge
represents a landmark initiative in this emerging field, responding to the pressing demand for precise
and scalable techniques for estimating food portions and monitoring nutritional consumption. Such
which capture red-green-blue (RGB) and depth data 2-3 hours daily (during daylight hours at times when participants were at home).
The videos were then manually annotated to the nearest millisecond to provide localization labels. Multiple human labelers used
software called ELAN to watch up to 4 simultaneously-captured video files at a time. The resulting labeled data recorded the kitchen,
hallway, dining room, living room, stairs, and porch. The duration of labeled data recorded by the cameras for PD and HC is 72.84
and 75.31 hours, respectively, which provides a relatively balanced label set for our room-level classification. Finally, to evaluate
