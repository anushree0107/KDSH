 A strong justification for a forecast can be considered a well-reasoned supporting argument.
Previous work in this area includes identifying argument components such as claims, premises,
backing, rebuttals, and refutations, as well as mining arguments that support or oppose a particular
claim. Despite these efforts, it was found that crowdsourced justifications rarely adhere to these
established argumentation frameworks, even though such justifications are valuable for aggregating
forecasts.
Finally, several studies have focused on forecasting using datasets similar or identical to the one used
in this research. From a psychological perspective, researchers have explored strategies for enhancing
forecasting accuracy, such as utilizing top-performing forecasters (often called "superforecasters"),
explanation may appear to rely heavily on the prevailing opinion of the crowd and might be considered
weaker than a justification that presents specific, verifiable facts from external resources.
To clarify the terminology used: a "question" is defined as a statement that seeks information (e.g.,
"Will new legislation be implemented before a certain date?"). Questions have a defined start and
end date, and the period between these dates constitutes the "life" of the question. "Forecasters"
are individuals who provide a "forecast," which consists of a "prediction" and a "justification." The
prediction is a numerical representation of the likelihood of an event occurring. The justification
is the text provided by the forecaster to support their prediction.industries as it enables them to anticipate and address potential challenges. This study focuses on
questions spanning the political, economic, and social domains, utilizing forecasts submitted by a
crowd of individuals without specialized training. Each forecast comprises a prediction and a natural
language justification.
6
The research demonstrates that aggregating the weighted predictions of forecasters is a solid baseline
for calling a question throughout its duration. However, models that incorporate both the question
and the justifications achieve significantly better results, particularly during the first three quartiles of
a questionâ€™s life. Importantly, the models developed in this study do not profile individual forecasters
or utilize any information about their identities. This work lays the groundwork for evaluating the
