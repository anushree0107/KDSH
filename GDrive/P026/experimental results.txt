Mbacke et al. (2023), and the proofs presented are fundamental.
1 Introduction
Diffusion models, alongside generative adversarial networks and variational autoencoders (V AEs), are among the most influential
families of deep generative models. These models have demonstrated remarkable empirical results in generating images and audio,
as well as in various other applications.
Two primary methods exist for diffusion models: denoising diffusion probabilistic models (DDPMs) and score-based generative
models (SGMs). DDPMs incrementally convert samples from the desired distribution into noise via a forward process, while
simultaneously training a backward process to reverse this transformation, enabling the creation of new samples.InceptionV3 5.3 mph
InceptionV3 + LSTM 4.5 mph
InceptionV3 + sub-events 3.6 mph
6.2.3 Pitch Type Classification
We conducted experiments to determine the feasibility of predicting pitch types from video, a task
made challenging by pitchers’ efforts to disguise their pitches from batters and the subtle differences
between pitches, such as grip and rotation. We incorporated pose data extracted using OpenPose,
utilizing heatmaps of joint and body part locations as input to a newly trained InceptionV3 CNN.
Pose features were considered due to variations in body mechanics between different pitches. Our
dataset includes six pitch types, with results presented in Table 7.was computed and clipped to [−20,20]. For InceptionV3, features were computed every 3 frames
(8 fps), while for I3D, every frame was used, with I3D having a temporal stride of 8, resulting in
3 features per second (3 fps). Models were implemented in PyTorch and trained using the Adam
optimizer with a learning rate of 0.01, decayed by a factor of 0.1 every 10 epochs, for a total of 50
epochs.
4
6.2 Segmented Video Activity Recognition
We initially conducted binary pitch/non-pitch classification for each video segment. This task is
