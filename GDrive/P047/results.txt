02426 230×265 (294 ×431×2.353)
7 Burger 0.1043478261 0.02435 208×264 (378 ×400×2.353)
8 Cake 0.1276595745 0.02143 256×300 (298 ×310×4.706)
9 Blueberry muffin 0.08759124088 0.01801 291×357 (441 ×443×2.353)
10 Banana 0.08759124088 0.01705 315×377 (446 ×857×1.176)
Medium 11 Salmon 0.1043478261 0.applicability.
•Complex backgrounds and objects: The method has not been tested in environments with
complex backgrounds or highly intricate food objects.
•Capturing complexities: The method has not been evaluated under different capturing
complexities, such as varying distances and camera speeds.
•Pipeline complexity: For one-shot neural rendering, the team currently uses One-2-3-45.
They aim to use only the 2D diffusion model, Zero123, to reduce complexity and improve
efficiency.
6
Table 3: Quantitative Comparison with Ground Truth Using Chamfer Distance
L Id Team’s V ol. GT V ol. Ch. w/ t.m Ch. w/o t.m
1 40.06 38.Participants were tasked with creating 3D models of 20 distinct food items from 2D images, mim-
icking scenarios where mobile devices equipped with depth-sensing cameras are used for dietary
.
recording and nutritional tracking. The challenge was segmented into three tiers of difficulty based
on the number of images provided: approximately 200 images for easy, 30 for medium, and a single
top-view image for hard. This design aimed to rigorously test the adaptability and resilience of
proposed solutions under various realistic conditions. A notable feature of this challenge was the use
of a visible checkerboard for physical referencing and the provision of depth images for each frame,
