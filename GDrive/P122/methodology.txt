0264
InvCF 0.0444 0.0344 0.0291 0.1001 0.1202 0.0662 0.0562 0.0665 0.0515
Adap- Ï„ 0.0450 0.0497 0.0341 0.1182 0.1248 0.0794 0.0641 0.0678 0.0511
SimGCL 0.0449 0.0518 0.0345 0.1194 0.1228 0.0804 0.0628 0.0648 0.0525
three elements: (a) a binary flag indicating whether the forecast was submitted on the day the question
is being called or on a previous day, (b) the prediction itself (a numerical value between 0.0 and 1.0),
and (c) a representation of the justification. The representation of the justification is also obtained
using BERT, followed by a fully connected layer with 256 neurons, ReLU activation, and dropout.
The LSTM has a hidden state with a dimensionality of 256 and processes the sequence of forecasts
as its input. During the tuning process, it was discovered that providing the representation of the
question alongside each forecast is more effective than processing forecasts independently of the
question.Data Models Kitch-Livin Kitch-Dinin Dinin-Livin
Ground Truth 18.71 (18.52) 14.65 (6.03) 10.64 (11.99)
ALL-HCRF 16.18 (12.08) 14.58 (10.22) 10.19 (9.46)
TENER 15.58 (8.75) 16.30 (12.94) 12.01 (13.01)
Alt DTML 15.27 (7.51) 13.40 (6.43) 10.84 (10.81)
MDCSA 17.70 (16.