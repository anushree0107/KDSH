Safe Predictors for Input-Output Specification
Enforcement
Abstract
This paper presents an approach for designing neural networks, along with other
machine learning models, which adhere to a collection of input-output specifica-
tions. Our method involves the construction of a constrained predictor for each set
of compatible constraints, and combining these predictors in a safe manner using a
convex combination of their predictions. We demonstrate the applicability of this
method with synthetic datasets and on an aircraft collision avoidance problem.
1 Introduction
The increasing adoption of machine learning models, such as neural networks, in safety-critical
applications, such as autonomous vehicles and aircraft collision avoidance, highlights an urgent
need for the development of guarantees on safety and robustness.the specifications until after training. Our work seeks to design networks with enforced input-output
constraints even before training has been completed. This will allow for online learning scenarios
where a system has to guarantee safety throughout its operation.
This paper presents an approach for designing a safe predictor (a neural network or any other
machine learning model) that will always meet a set of constraints on the input-output relationship.
This assumes that the constrained output regions can be formulated to be convex. Our correct-
by-construction safe predictor is guaranteed to satisfy the constraints, even before training, and at
every training step. We describe our approach in Section 2, and show its use in an aircraft collision
avoidance problem in Section 3. Furthermore, we introduce a modified
version of EG that incorporates an adaptive step size, eliminating the need for prior knowledge of the problemâ€™s
specific parameters.
1 Introduction
The recent advancements in machine learning models, particularly those that can be formulated as min-max optimization problems,
have generated significant interest in saddle point problems. Examples of these models include generative adversarial networks,
adversarial learning frameworks, adversarial example games, and actor-critic methods. While practical methods have been developed
that generally perform well, the theoretical understanding of scenarios where the objective function is nonconvex in the minimization
component and nonconcave in the maximization component remains limited, with some research even suggesting intractability in
certain cases.
