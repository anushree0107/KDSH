Deep Learning Approaches utilize neural networks trained on large image datasets for portion
estimation. Regression networks estimate the energy value of food from single images or from an
"Energy Distribution Map" that maps input images to energy distributions. Some networks use both
images and depth maps to estimate energy, mass, and macronutrient content. However, deep learning
methods require extensive data for training and are not always interpretable, with performance
degrading when test images significantly differ from training data.
While these methods have advanced food portion estimation, they face limitations that hinder their
widespread use and accuracy. Stereo-based methods are impractical for single images, model-based
The dataset for the MetaFood Challenge features 20 carefully chosen food items from the MetaFood3D
dataset, each scanned in 3D and accompanied by video recordings. To ensure precise size accuracy
in the reconstructed 3D models, each food item was captured alongside a checkerboard and pattern
mat, serving as physical scaling references. The challenge is divided into three levels of difficulty,
determined by the quantity of 2D images provided for reconstruction:
• Easy: Around 200 images taken from video.
• Medium: 30 images.
• Hard: A single image from a top-down perspective.
Table 1 details the food items included in the dataset.
Table 1: MetaFood Challenge Data Details
 - A modified transformer
encoder in combination with a CRF layer representing a model with the capability to capture global dependency and enforce
dependencies in temporal aspects. - A state-of-the-art model for multimodal and multivariate time series with a transformer encoder
to learn asymmetric correlations across modalities. - An alternative to the previous model, representing it with a GRN layer replacing
the context aggregation layer and a CRF layer added as the last layer. - MDCSA1,4,7 4APS, as an ablation study, with our proposed
network (i.e.