applicability.
•Complex backgrounds and objects: The method has not been tested in environments with
complex backgrounds or highly intricate food objects.
•Capturing complexities: The method has not been evaluated under different capturing
complexities, such as varying distances and camera speeds.
•Pipeline complexity: For one-shot neural rendering, the team currently uses One-2-3-45.
They aim to use only the 2D diffusion model, Zero123, to reduce complexity and improve
efficiency.
6
Table 3: Quantitative Comparison with Ground Truth Using Chamfer Distance
L Id Team’s V ol. GT V ol. Ch. w/ t.m Ch. w/o t.m
1 40.06 38.The dataset for the MetaFood Challenge features 20 carefully chosen food items from the MetaFood3D
dataset, each scanned in 3D and accompanied by video recordings. To ensure precise size accuracy
in the reconstructed 3D models, each food item was captured alongside a checkerboard and pattern
mat, serving as physical scaling references. The challenge is divided into three levels of difficulty,
determined by the quantity of 2D images provided for reconstruction:
• Easy: Around 200 images taken from video.
• Medium: 30 images.
• Hard: A single image from a top-down perspective.
Table 1 details the food items included in the dataset.
Table 1: MetaFood Challenge Data Details
35 8.64
20 117.43 119.83 20.03
6 Best 3D Mesh Reconstruction Team - FoodRiddle
6.1 Methodology
To achieve high-fidelity food mesh reconstruction, the team developed two procedural pipelines as
depicted in Figure 14. For simple and medium complexity cases, they employed a structure-from-
motion strategy to ascertain the pose of each image, followed by mesh reconstruction. Subsequently,
a sequence of post-processing steps was implemented to recalibrate the scale and improve mesh
quality. For cases involving only a single image, the team utilized image generation techniques to
facilitate model generation.
6.1.1 Multi-View Reconstruction
