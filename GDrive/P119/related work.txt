In computational linguistics, noun-noun compound interpretation is typically treated as an automatic
classification task. Various machine learning (ML) algorithms and models, such as Maximum
Entropy, Support Vector Machines, and Neural Networks, have been employed to decipher the
semantics of nominal compounds. These models utilize information from lexical semantics, like
WordNet-based features, and distributional semantics, such as word embeddings. However, noun-
noun compound interpretation remains a challenging NLP problem due to the high productivity
of noun-noun compounding as a linguistic structure and the difficulty in deriving the semantics of
noun-noun compounds from their constituents. Our research contributes to advancing NLP research
t=1LBCE(ˆft, ft) (10)
LLL(ˆe, y) =TX
i=0P(φ(hi))qT
i(yi|yi−1)−TX
i=0P(φ(hi))[qT
i(yi|yi−1)] (11)
5
LBCE(ˆf, f) =−1
TTX
t=0ftlog(ˆft) + (1 −ft) log(1 −ˆft) (12)
where LLL(.)represents the negative log-likelihood and LBCE(.)denotes the binary cross-entropy, y= [y1, ...01786 320×360 (238 ×257×2.353)
2 Cinnamon bun 0.1043478261 0.02347 236×274 (363 ×419×2.353)
3 Pork rib 0.1043478261 0.02381 246×270 (435 ×778×1.176)
Easy 4 Corn 0.08823529412 0.01897 291×339 (262 ×976×2.353)
5 French toast 0.1034482759 0.02202 266×292 (530 ×581×2.53)
6 Sandwich 0.1276595745 0.