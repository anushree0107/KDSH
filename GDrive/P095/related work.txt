but the label sets are distinct.
For clarity, we differentiate between transfer learning and multi-task learning in this paper, despite
these terms sometimes being used interchangeably in the literature. We define TL as the utilization of
parameters from a model trained on Ta to initialize another model for Tb. In contrast, MTL involves
training parts of the same model to learn both Ta and Tb, essentially learning one set of parameters
for both tasks. The concept is to train a single model simultaneously on both tasks, where one task
introduces an inductive bias that aids the model in generalizing over the main task. It is important to
as shown in Table 2. We do not apply TL (or MTL) to the output layer because it is task- or
dataset-specific.
5.3 Multi-Task Learning Models
In MTL, we train a single model to simultaneously learn both PCEDT and NomBank relations,
meaning all MTL models have two objective functions and two output layers. We implement two
MTL setups: MTLE, which features a shared embedding layer but two task-specific hidden layers,
and MTLF, which has no task-specific layers aside from the output layer (i.e., both the embedding
and hidden layers are shared). We distinguish between the auxiliary and main tasks based on which
3 53.4 57.2
I3D + pyramid 53.2 56.7 58.7
I3D + LSTM 48.2 53.1 53.1
I3D + temporal conv 52.8 57.1 58.4
I3D + sub-events 55.5 61.2 61.3
Table 5 shows the average precision for each activity class. Learning temporal structure is particularly
beneficial for frame-based features (e.g., InceptionV3), which capture less temporal information
5
compared to segment-based features (e.g., I3D). Sub-event learning significantly aids in detecting
