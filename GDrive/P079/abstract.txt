highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research
concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the
relatively recent dataset from Fares (2016).
2 Related Work
Approaches to interpreting noun-noun compounds differ based on the classification of compound
relations, as well as the machine learning models and features employed to learn these relations. For
instance, some define a broad set of relations, while others employ a more detailed classification.
Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed,
predetermined set of relations, proposing alternative methods based on paraphrasing. We center
Broader Impact
Supervised machine learning now affects both personal and public lives significantly. Generalization is
critical to the reliability and safety of empirically trained models. Our analysis aims to achieve a deeper
understanding of the relationships between generalization, architectural design, and available data.
We have discussed the concepts and demonstrated the effectiveness of using uniform concentration
events for generalization guarantees of common supervised machine learning algorithms.
7
• a standard neural network architecture gb:X→Rm,
and then defining Gb(x;θb) =hb(gb(x;θb)).
The framework proposed here does not require an entirely separate network for each b. In many
applications, it may be advantageous for the constrained predictors to share earlier layers, thus
creating a shared representation of the input space. In addition, our definition of the safe predictor is
general and is not limited to neural networks.
In Appendix B, we show examples of applying our approach to synthetic datasets in 2-D and 3-D
with simple neural networks. These examples show that our safe predictor can enforce arbitrary
input-output specifications using convex output constraints on neural networks, and that the learned
