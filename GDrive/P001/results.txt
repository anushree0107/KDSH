34 23.98
20 130.96 119.83 15.59 31.05
Table 4: Quantitative Comparison with Ground Truth Using MAPE and Chamfer Distance
MAPE Ch. w/ t.m Ch. w/o t.m
(%) sum mean sum mean
10.973 0.130 0.007 1.715 0.095
5 Second Place Team - ININ-VIAUN
5.1 Methodology
This section details the team’s proposed network, illustrating the step-by-step process from original
images to final mesh models.
5.1.1 Scale factor estimation
two TL models (TLE improves over the STL accuracy by 1.37 points).
Table 2: Accuracy (%) of the transfer learning models.
Model NomBank PCEDT
Dev Test Dev Test
STL 78.15 76.75 58.80 56.05
TLE 78.37 78.05 59.57 57.42
TLH 78.15 78.00 59.24 56.51
TLEH 78.48 78.00 59.89 56.68
Table 3: Accuracy (%) of the MTL models.
Model NomBank PCEDT
Dev Test Dev Test
STL 78.i=1, keyframes {IK
j}k
j=1⊆ {IDi}n
i=1are
chosen. A method is implemented to detect and remove duplicate and blurry images, ensuring
high-quality frames. This involves applying a Gaussian blurring kernel followed by the fast Fourier
transform method. Near-Image Similarity uses perceptual hashing and Hamming distance threshold-
ing to detect similar images and retain overlapping ones. Duplicates and blurry images are excluded
to maintain data integrity and accuracy.
Using the selected keyframes {IK
j}k
j=1, the team estimates camera poses through a method called
