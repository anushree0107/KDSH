 The central problem addressed in
this work is termed "calling a question," which refers to the process of determining a final prediction
by aggregating individual forecasts. Two strategies are employed for calling questions each day
throughout their life: considering forecasts submitted on the given day ("daily") and considering the
last forecast submitted by each forecaster ("active").
Inspired by prior research on recognizing and fostering skilled forecasters, and analyzing written
justifications to assess the quality of individual or collective forecasts, this paper investigates the
automated calling of questions throughout their duration based on the forecasts available each day.
The primary contributions are empirical findings that address the following research questions:
smartphone IMU sensor data and Wi-Fi-received signal strength indication (RSSI) measurements to estimate the exact location (in
Euclidean position X, Y) of a person in indoor environments. The proposed sensor fusion framework uses location fingerprinting in
combination with a pedestrian dead reckoning (PDR) algorithm to reduce positioning errors.
Looking at this multi-modality classification/regression problem from a time series perspective, there has been a lot of exploration
in tackling a problem where each modality can be categorized as multivariate time series data. LSTM and attention layers are
often used in parallel to directly transform raw multivariate time series data into a low-dimensional feature representation for each
modality.t+bu) +τt (1)
where Wu∈Ru×dandbu∈Rdare the weight and bias to learn, dis the embedding dimension, and τt∈Rdis the corresponding
position encoding at time t.
4.2 Locality Enhancement with Self-Attention
Since it is time-series data, the importance of an RSSI or accelerometer value at each point in time can be identified in relation to its
surrounding values - such as cyclical patterns, trends, or fluctuations. Utilizing historical context that can capture local patterns on
top of point-wise values, performance improvements in attention-based architectures can be achieved. One straightforward option is
