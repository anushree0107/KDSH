02021 249×318 (186 ×95×0.987)
19 Waffle 0.01034482759 0.01902 294×338 (465 ×537×0.8)
20 Pizza 0.01034482759 0.01913 292×336 (442 ×651×1.176)
After finding keyframes, PixSfM estimated the poses and point cloud. After generating scaled meshes,
the team calculated volumes and Chamfer distance with and without transformation metrics. Meshes
were registered with ground truth meshes using ICP to obtain transformation metrics.
Table 3 presents quantitative comparisons of the team’s volumes and Chamfer distance with and
without estimated transformation metrics from ICP.metric. Given two point sets XandY, the Chamfer distance is defined as:
dCD(X, Y ) =1
|X|X
x∈Xmin
y∈Y∥x−y∥2
2+1
|Y|X
y∈Ymin
x∈X∥x−y∥2
2 (2)
This metric offers a comprehensive measure of similarity between the reconstructed 3D models and
the ground truth. The final ranking is determined by combining scores from both Phase-I (volume
accuracy) and Phase-II (shape accuracy). Note that after the Phase-I evaluation, quality issues were
The procedure for estimating the scale factor at the coordinate level is illustrated in Figure 9. The
team adheres to a method involving corner projection matching. Specifically, utilizing the COLMAP
dense model, the team acquires the pose of each image along with dense point cloud data. For any
given image imgkand its extrinsic parameters [R|t]k, the team initially performs threshold-based
corner detection, setting the threshold at 240. This step allows them to obtain the pixel coordinates
of all detected corners. Subsequently, using the intrinsic parameters kand the extrinsic parameters
[R|t]k, the point cloud is projected onto the image plane. Based on the pixel coordinates of the
