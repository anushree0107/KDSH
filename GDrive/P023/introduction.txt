 Inspired by utilizing multihead self-attention, we utilize our DCSA with various kernel lengths with the same
aim: allowing asymmetric long-term learning. The multihead DCSA takes in two inputs ˆx1,ˆx2∈RN×dand yields:
MDCSA k1,...,k n(ˆx1,ˆx2) = Ξ n(φk1,...,k n(ˆx1,ˆx2)) (4)
with
is a 1D-convolutional layer with a kernel size {1, k}and a stride
of 1,WK∈Rd×d, WQ∈Rd×d, WV∈Rd×dare weights for keys, queries, and values of the self-attention layer, and dis the
embedding dimension. Note that all weights for GRN are shared across each time step t.
4
4.3 Multihead Dual Convolutional Self-Attention
Our approach employs a self-attention mechanism to capture global dependencies across time steps. It is embedded as part of the
DCSA architecture.π((t−xn)2+γ2n)exp(1−2|tanh( γ′
n)|)
where Znis a normalization constant, t∈ {1,2, . . . , T }, and n∈ {1,2, . . . , N }.
The filters are combined with learned per-class soft-attention weights A, and the super-event repre-
sentation is computed as:
Sc=X
nAc,nX
tfn(t)·vt
where vis the T×Dvideo representation. These filters enable the model to focus on relevant
intervals for temporal context. The super-event representation is concatenated to each timestep and
used for classification.