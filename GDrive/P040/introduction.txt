would also increase the generalizability of the results to the wider population. Future work in this matter could also include the
construction of a semi-synthetic dataset based on collected data to facilitate a parallel and large-scale evaluation.
This smart home’s layout and parameters remain constant for all the participants, and we acknowledge that the transfer of this deep
learning model to other varied home settings may introduce variations in localization accuracy. For future ecological validation and
based on our current results, we anticipate the need for pre-training (e.g., a brief walkaround which is labeled) for each home, and
also suggest that some small amount of ground-truth data will need to be collected (e.g., researcher prompting of study participants to
 We also experiment with combining the super- and sub-event representations
to form a three-level hierarchy for event representation.
6 Experiments
6.1 Implementation Details
For our base per-segment CNN, we utilize the I3D network, pre-trained on the ImageNet and Kinetics
datasets. I3D has achieved state-of-the-art performance on segmented video tasks, providing a reliable
feature representation. We also employ a two-stream version of InceptionV3, pre-trained on Imagenet
and Kinetics, as our base per-frame CNN for comparison. InceptionV3 was chosen for its depth
compared to previous two-stream CNNs. Frames were extracted at 25 fps, and TVL1 optical flow
• a standard neural network architecture gb:X→Rm,
and then defining Gb(x;θb) =hb(gb(x;θb)).
The framework proposed here does not require an entirely separate network for each b. In many
applications, it may be advantageous for the constrained predictors to share earlier layers, thus
creating a shared representation of the input space. In addition, our definition of the safe predictor is
general and is not limited to neural networks.
In Appendix B, we show examples of applying our approach to synthetic datasets in 2-D and 3-D
with simple neural networks. These examples show that our safe predictor can enforce arbitrary
input-output specifications using convex output constraints on neural networks, and that the learned
