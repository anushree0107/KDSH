highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research
concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the
relatively recent dataset from Fares (2016).
2 Related Work
Approaches to interpreting noun-noun compounds differ based on the classification of compound
relations, as well as the machine learning models and features employed to learn these relations. For
instance, some define a broad set of relations, while others employ a more detailed classification.
Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed,
predetermined set of relations, proposing alternative methods based on paraphrasing. We center
observed on the ’most challenging’ inputs that include at least one constituent that was not present in
the training data. However, clear indications of ’lexical memorization’ effects are evident in our error
analysis of unseen compounds.
Typically, the transfer of representations or sharing between tasks is more effective at the embedding
layers, which represent the model’s internal representation of the compound constituents. Furthermore,
in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity
to generalize when it comes to less frequent relations.
The dataset provided by Fares (2016) is an appealing resource for new neural approaches to compound
interpretation because it links this sub-problem with broad-coverage semantic role labeling or
 Our goal is to learn a function f(X) that predicts Y based on the input features X.
Considering two ML tasks, Ta and Tb, we would train two distinct models to learn separate functions
fa and fb for predicting Ya and Yb in a single-task learning scenario. However, if Ta and Tb are
related, either explicitly or implicitly, TL and MTL can enhance the generalization of either or both
tasks. Two tasks are deemed related when their domains are similar but their label sets differ, or when
their domains are dissimilar but their label sets are identical. Consequently, noun-noun compound
interpretation using the dataset is well-suited for TL and MTL, as the training examples are identical,
