highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research
concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the
relatively recent dataset from Fares (2016).
2 Related Work
Approaches to interpreting noun-noun compounds differ based on the classification of compound
relations, as well as the machine learning models and features employed to learn these relations. For
instance, some define a broad set of relations, while others employ a more detailed classification.
Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed,
predetermined set of relations, proposing alternative methods based on paraphrasing. We center
79%, and 82.89% in NDCG@20 on the
Yelp2018, Gowalla, and Amazon-Book datasets, respectively. Compared to the strongest baselines, PAAC delivers better
performance. The most significant improvements are observed on Yelp2018, where our model achieves an 8.70% increase
in Recall@20, a 10.81% increase in HR@20, and a 30.2% increase in NDCG@20. This improvement can be attributed
to our use of popularity-aware supervised alignment to enhance the representation of less popular items and re-weighted
contrastive learning to address representation separation from a popularity-centric perspective.
different positive and negative samples to mitigate representation separation from a popularity-centric perspective. We incorporate
this approach into contrastive learning to better optimize the consistency of representations. Specifically, we aim to reduce the risk
of pushing items with varying popularity further apart. For example, when using a popular item as a positive sample, our goal is
to avoid pushing unpopular items too far away. Thus, we introduce two hyperparameters to control the weights when items are
considered positive and negative samples.
To ensure balanced and equitable representations of items within our model, we first propose a dynamic strategy to categorize items
into popular and unpopular groups for each mini-batch. Instead of relying on a fixed global threshold, which often leads to the
