highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research
concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the
relatively recent dataset from Fares (2016).
2 Related Work
Approaches to interpreting noun-noun compounds differ based on the classification of compound
relations, as well as the machine learning models and features employed to learn these relations. For
instance, some define a broad set of relations, while others employ a more detailed classification.
Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed,
predetermined set of relations, proposing alternative methods based on paraphrasing. We center
baselines only in the first three quartiles. In the last quartile, the neural networks perform significantly
worse than the baselines. This suggests that while modeling questions and justifications is generally
helpful, it becomes detrimental toward the end of a questionâ€™s life. This phenomenon can be attributed
to the increasing wisdom of the crowd as more evidence becomes available and more forecasters
contribute, making their aggregated predictions more accurate.
5
Table 4: Results with the test questions, categorized by question difficulty as determined by the best
baseline model. The table presents the accuracy (average percentage of days a question is predicted
our attention on methods that frame the interpretation problem as a classification task involving a
fixed, predetermined set of relations. Various machine learning models have been applied to this
task, including nearest neighbor classifiers that use semantic similarity based on lexical resources,
kernel-based methods like SVMs that utilize lexical and relational features, Maximum Entropy
models that incorporate a wide range of lexical and surface form features, and neural networks that
rely on word embeddings or combine word embeddings with path embeddings. Among these studies,
some have utilized the same dataset. To our knowledge, TL and MTL have not been previously
applied to compound interpretation. Therefore, we review prior research on TL and MTL in other
NLP tasks.
