Hamming distance for near image similarity was set to 12. For Gaussian kernel radius, even numbers
in the range [0...30] were used for detecting blurry images. The diameter for removing isolated pieces
was set to 5%. NeuS2 was run for 15,000 iterations with a mesh resolution of 512x512, a unit cube
"aabb scale" of 1, "scale" of 0.15, and "offset" of [0.5, 0.5, 0.5] for each food scene.
5
4.2.2 VolETA Results
The team extensively validated their approach on the challenge dataset and compared their results
factors, PPU, 2D reference object dimensions, 3D food object dimensions, and potential volume.
For one-shot 3D reconstruction, the team uses One-2-3-45 to reconstruct a 3D model from a single
RGBA view input after applying binary image segmentation to both food RGB and mask images.
Isolated pieces are removed from the generated mesh, and the scaling factor S, which is closer to the
potential volume of the clean mesh, is reused.
4.2 Experimental Results
4.2.1 Implementation settings
Experiments were conducted using two GPUs: GeForce GTX 1080 Ti/12G and RTX 3060/6G. The
found with the data for object 12 (steak) and object 15 (chicken nugget), so these items were excluded
from the final overall evaluation.
4 First Place Team - VolETA
4.1 Methodology
The team’s research employs multi-view reconstruction to generate detailed food meshes and calculate
precise food volumes.
4.1.1 Overview
The team’s method integrates computer vision and deep learning to accurately estimate food volume
from RGBD images and masks. Keyframe selection ensures data quality, supported by perceptual
hashing and blur detection. Camera pose estimation and object segmentation pave the way for neural
surface reconstruction, creating detailed meshes for volume estimation. Refinement steps, including
