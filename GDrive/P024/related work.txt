Broader Impact
Supervised machine learning now affects both personal and public lives significantly. Generalization is
critical to the reliability and safety of empirically trained models. Our analysis aims to achieve a deeper
understanding of the relationships between generalization, architectural design, and available data.
We have discussed the concepts and demonstrated the effectiveness of using uniform concentration
events for generalization guarantees of common supervised machine learning algorithms.
7
• a standard neural network architecture gb:X→Rm,
and then defining Gb(x;θb) =hb(gb(x;θb)).
The framework proposed here does not require an entirely separate network for each b. In many
applications, it may be advantageous for the constrained predictors to share earlier layers, thus
creating a shared representation of the input space. In addition, our definition of the safe predictor is
general and is not limited to neural networks.
In Appendix B, we show examples of applying our approach to synthetic datasets in 2-D and 3-D
with simple neural networks. These examples show that our safe predictor can enforce arbitrary
input-output specifications using convex output constraints on neural networks, and that the learned
use in safety-critical machine learning systems, demonstrating it on an aircraft collision avoidance
problem. The novelty of our approach is its simplicity and guaranteed enforcement of specifications
through combinations of convex output constraints during all stages of training. Future work includes
adapting and using techniques from optimization and control barrier functions, as well as incorporating
notions of adversarial robustness into our design, such as extending the work to bound the Lipschitz
constant of our networks.
Appendix A: Proof of Theorem 2.1
Proof. Fixiand assume that x∈Ai. It follows that σi(x) = 0 , so for all b∈Owhere bi= 0,
