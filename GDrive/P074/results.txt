the full ranking strategy, considering all non-interacted items as candidate items to avoid selection bias during the test stage. We
repeated each experiment five times with different random seeds and reported the average scores.
3.2 Overall Performance
As shown in Table 1, we compare our model with several baselines across three datasets. The best performance for each metric
is highlighted in bold, while the second best is underlined. Our model consistently outperforms all compared methods across all
metrics in every dataset.
•Our proposed model PAAC consistently outperforms all baselines and significantly mitigates the popularity bias. Specif-
ically, PAAC enhances LightGCN, achieving improvements of 282.65%, 180.found with the data for object 12 (steak) and object 15 (chicken nugget), so these items were excluded
from the final overall evaluation.
4 First Place Team - VolETA
4.1 Methodology
The team’s research employs multi-view reconstruction to generate detailed food meshes and calculate
precise food volumes.
4.1.1 Overview
The team’s method integrates computer vision and deep learning to accurately estimate food volume
from RGBD images and masks. Keyframe selection ensures data quality, supported by perceptual
hashing and blur detection. Camera pose estimation and object segmentation pave the way for neural
surface reconstruction, creating detailed meshes for volume estimation. Refinement steps, including
note that this does not necessarily imply that we aim to use a single model to predict both label sets
in practice.
5 Neural Classification Models
This section introduces the neural classification models utilized in our experiments. To discern the
impact of TL and MTL, we initially present a single-task learning model, which acts as our baseline.
Subsequently, we employ this same model to implement TL and MTL.
5.1 Single-Task Learning Model
In our single-task learning (STL) configuration, we train and fine-tune a feed-forward neural network
inspired by the neural classifier proposed by Dima and Hinrichs (2015). This network comprises four
