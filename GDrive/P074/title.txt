The dataset for the MetaFood Challenge features 20 carefully chosen food items from the MetaFood3D
dataset, each scanned in 3D and accompanied by video recordings. To ensure precise size accuracy
in the reconstructed 3D models, each food item was captured alongside a checkerboard and pattern
mat, serving as physical scaling references. The challenge is divided into three levels of difficulty,
determined by the quantity of 2D images provided for reconstruction:
• Easy: Around 200 images taken from video.
• Medium: 30 images.
• Hard: A single image from a top-down perspective.
Table 1 details the food items included in the dataset.
Table 1: MetaFood Challenge Data Details
Advancements in 3D Food Modeling: A Review of the
MetaFood Challenge Techniques and Outcomes
Abstract
The growing focus on leveraging computer vision for dietary oversight and nutri-
tion tracking has spurred the creation of sophisticated 3D reconstruction methods
for food. The lack of comprehensive, high-fidelity data, coupled with limited
collaborative efforts between academic and industrial sectors, has significantly
hindered advancements in this domain. This study addresses these obstacles by
introducing the MetaFood Challenge, aimed at generating precise, volumetrically
accurate 3D food models from 2D images, utilizing a checkerboard for size cal-
ibration. The challenge was structured around 20 food items across three levels
found with the data for object 12 (steak) and object 15 (chicken nugget), so these items were excluded
from the final overall evaluation.
4 First Place Team - VolETA
4.1 Methodology
The team’s research employs multi-view reconstruction to generate detailed food meshes and calculate
precise food volumes.
4.1.1 Overview
The team’s method integrates computer vision and deep learning to accurately estimate food volume
from RGBD images and masks. Keyframe selection ensures data quality, supported by perceptual
hashing and blur detection. Camera pose estimation and object segmentation pave the way for neural
surface reconstruction, creating detailed meshes for volume estimation. Refinement steps, including
