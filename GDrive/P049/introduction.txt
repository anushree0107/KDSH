Advanced techniques for through and contextually
Interpreting Noun-Noun Compounds
Abstract
This study examines the effectiveness of transfer learning and multi-task learning
in the context of a complex semantic classification problem: understanding the
meaning of noun-noun compounds. Through a series of detailed experiments and
an in-depth analysis of errors, we demonstrate that employing transfer learning by
initializing parameters and multi-task learning through parameter sharing enables a
neural classification model to better generalize across a dataset characterized by a
highly uneven distribution of semantic relationships. Furthermore, we illustrate
how utilizing dual annotations, which involve two distinct sets of relations applied
to the same compounds, can enhance the overall precision of a neural classifier and
observed on the ’most challenging’ inputs that include at least one constituent that was not present in
the training data. However, clear indications of ’lexical memorization’ effects are evident in our error
analysis of unseen compounds.
Typically, the transfer of representations or sharing between tasks is more effective at the embedding
layers, which represent the model’s internal representation of the compound constituents. Furthermore,
in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity
to generalize when it comes to less frequent relations.
The dataset provided by Fares (2016) is an appealing resource for new neural approaches to compound
interpretation because it links this sub-problem with broad-coverage semantic role labeling or
 Our goal is to learn a function f(X) that predicts Y based on the input features X.
Considering two ML tasks, Ta and Tb, we would train two distinct models to learn separate functions
fa and fb for predicting Ya and Yb in a single-task learning scenario. However, if Ta and Tb are
related, either explicitly or implicitly, TL and MTL can enhance the generalization of either or both
tasks. Two tasks are deemed related when their domains are similar but their label sets differ, or when
their domains are dissimilar but their label sets are identical. Consequently, noun-noun compound
interpretation using the dataset is well-suited for TL and MTL, as the training examples are identical,
