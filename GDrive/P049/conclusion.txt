Assumption 2, consists of mindependent copies of the random pair (x, y). During training, the
interpolation quality of a hypothesis function f:X → Y can only be assessed at the given random
samples {xj}m
j=1. Any algorithm therefore accesses each function fthrough its sketch samples
S[f] = (f(x1), . . . , f (xm)),
2
where Sis the sample operator. After training, the quality of a resulting model is often measured by
its generalization to new data not used during training. With Rd×Ras the input and output space,
we quantify a function f’s generalization error with its expected risk:
suming the NeuRIPs event, we then provide bounds on the expected risk, applicable
to networks within any sublevel set of the empirical risk. Our results show that all
networks with sufficiently small empirical risk achieve uniform generalization.
1 Introduction
A fundamental requirement of any scientific model is a clear evaluation of its limitations. In recent
years, supervised machine learning has seen the development of tools for automated model discovery
from training data. However, these methods often lack a robust theoretical framework to estimate
model limitations. Statistical learning theory quantifies the limitation of a trained model by the
generalization error. This theory uses concepts such as the VC-dimension and Rademacher complexity
to analyze generalization error bounds for classification problems.are updated during the training of all models. We utilize the Adaptive Moment Estimation (Adam)
optimization function across all models, with a learning rate set to 0.001. The loss function employed
is the negative-log likelihood. A Sigmoid activation function is used for the units in the hidden layer.
All models are trained with mini-batches of size five. The maximum number of epochs is capped
at 50, but an early stopping criterion based on the model’s accuracy on the validation split is also
implemented. This means that training is halted if the validation accuracy does not improve over five
consecutive epochs. All models are implemented in Keras, using TensorFlow as the backend. The TL
