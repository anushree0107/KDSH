We define our networks and perform parameter optimization using PyTorch. We optimize the
parameters of both the unconstrained network and our safe predictor using the asymmetric loss
function, guiding the network to select optimal advisories while accurately predicting scores from
the look-up tables. Each dataset is split using an 80/20 train/test split, with a random seed of 0. The
optimizer is ADAM, with a learning rate of 0.0003, a batch size of 216, and the number of training
epochs is 500.
6
neural network configurations, except for the one using only predictions and justifications.
**Encoding Questions and Justifications** The neural network that only utilizes the prediction
to represent a forecast surpasses both baseline methods. Notably, integrating the question, the
justification, or both into the forecast representation yields further improvements. These results
indicate that incorporating the question and forecaster-provided justifications into the model enhances
the accuracy of question calling.
**Calling Questions Throughout Their Life** When examining the results across the four quartiles of
a question’s duration, it’s observed that while using active forecasts is beneficial across all quartiles
for both baselines and all network configurations, the neural networks surprisingly outperform the
 Reluplex has also been used to
verify adversarial robustness. While Reluplex and other similar techniques can effectively determine
if a network satisfies a given specification, they do not offer a way to guarantee that the network will
meet those specifications. Therefore, additional methods are needed to adjust networks if it is found
that they are not meeting the desired properties.
There has been an increase in techniques for designing networks with certified adversarial robustness,
but enforcing more general safety properties in neural networks is still largely unexplored. One ap-
proach to achieving provably correct neural networks is through abstraction-refinement optimization.
This approach has been applied to the ACAS-Xu dataset, but the network was not guaranteed to meet
