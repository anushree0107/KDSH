was computed and clipped to [âˆ’20,20]. For InceptionV3, features were computed every 3 frames
(8 fps), while for I3D, every frame was used, with I3D having a temporal stride of 8, resulting in
3 features per second (3 fps). Models were implemented in PyTorch and trained using the Adam
optimizer with a learning rate of 0.01, decayed by a factor of 0.1 every 10 epochs, for a total of 50
epochs.
4
6.2 Segmented Video Activity Recognition
We initially conducted binary pitch/non-pitch classification for each video segment. This task is
1 35.8 37.3
InceptionV3 + super-events 31.5 36.2 39.6
InceptionV3 + sub+super-events 34.2 40.2 40.9
7 Conclusion
This paper introduces MLB-YouTube, a novel and challenging dataset designed for detailed activity
recognition in videos. We conduct a comparative analysis of various recognition techniques that
employ temporal feature pooling for both segmented and continuous videos. Our findings reveal that
learning sub-events to pinpoint temporal regions of interest significantly enhances performance in
segmented video classification. In the context of activity detection in continuous videos, we establish
Detailed Action Identification in Baseball Game
Recordings
Abstract
This research introduces MLB-YouTube, a new and complex dataset created for
nuanced activity recognition in baseball videos. This dataset is structured to
support two types of analysis: one for classifying activities in segmented videos
and another for detecting activities in unsegmented, continuous video streams. This
study evaluates several methods for recognizing activities, focusing on how they
capture the temporal organization of activities in videos. This evaluation starts
with categorizing segmented videos and progresses to applying these methods
to continuous video feeds. Additionally, this paper assesses the effectiveness of
different models in the challenging task of forecasting pitch velocity and type
using baseball broadcast videos. The findings indicate that incorporating temporal
