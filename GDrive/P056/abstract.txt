applicability.
•Complex backgrounds and objects: The method has not been tested in environments with
complex backgrounds or highly intricate food objects.
•Capturing complexities: The method has not been evaluated under different capturing
complexities, such as varying distances and camera speeds.
•Pipeline complexity: For one-shot neural rendering, the team currently uses One-2-3-45.
They aim to use only the 2D diffusion model, Zero123, to reduce complexity and improve
efficiency.
6
Table 3: Quantitative Comparison with Ground Truth Using Chamfer Distance
L Id Team’s V ol. GT V ol. Ch. w/ t.m Ch. w/o t.m
1 40.06 38.02426 230×265 (294 ×431×2.353)
7 Burger 0.1043478261 0.02435 208×264 (378 ×400×2.353)
8 Cake 0.1276595745 0.02143 256×300 (298 ×310×4.706)
9 Blueberry muffin 0.08759124088 0.01801 291×357 (441 ×443×2.353)
10 Banana 0.08759124088 0.01705 315×377 (446 ×857×1.176)
Medium 11 Salmon 0.1043478261 0.surfaces, and intricate geometries common in culinary subjects.
The competition involved 20 diverse food items, captured under various conditions and with differing
numbers of input images, specifically designed to challenge participants in creating robust reconstruc-
tion models. The evaluation was based on a two-phase process, assessing both portion size accuracy
through Mean Absolute Percentage Error (MAPE) and shape accuracy using the Chamfer distance
metric.
Of all participating teams, three reached the final submission stage, presenting a range of innovative
solutions. Team V olETA secured first place with the best overall performance in both Phase-I and
Phase-II, followed by team ININ-VIAUN in second place. Additionally, the FoodRiddle team
