 For overall method performance, Table 4 shows
the MAPE and Chamfer distance with and without transformation metrics.
Additionally, qualitative results on one- and few-shot 3D reconstruction from the challenge dataset
are shown. The model excels in texture details, artifact correction, missing data handling, and color
adjustment across different scene parts.
Limitations: Despite promising results, several limitations need to be addressed in future work:
•Manual processes: The current pipeline includes manual steps like providing segmentation
prompts and identifying scaling factors, which should be automated to enhance efficiency.
•Input requirements: The method requires extensive input information, including food
masks and depth data. Streamlining these inputs would simplify the process and increase
L/2,L/4, and L/8, resulting in 14 segments per window. Max-pooling is applied to each segment,
and the pooled features are concatenated, yielding a 14×D-dimensional representation for each
window, which is then used as input to the classifier.
For temporal convolutional models in continuous videos, we modify the segmented video approach by
learning a temporal convolutional kernel of length Land convolving it with the input video features.
This operation transforms input of size T×Dinto output of size T×D, followed by a per-frame
classifier. This enables the model to aggregate local temporal information.
 We also experiment with combining the super- and sub-event representations
to form a three-level hierarchy for event representation.
6 Experiments
6.1 Implementation Details
For our base per-segment CNN, we utilize the I3D network, pre-trained on the ImageNet and Kinetics
datasets. I3D has achieved state-of-the-art performance on segmented video tasks, providing a reliable
feature representation. We also employ a two-stream version of InceptionV3, pre-trained on Imagenet
and Kinetics, as our base per-frame CNN for comparison. InceptionV3 was chosen for its depth
compared to previous two-stream CNNs. Frames were extracted at 25 fps, and TVL1 optical flow
